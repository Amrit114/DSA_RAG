# DSA RAG

A small Retrieval-Augmented Generation (RAG) service that exposes a Flask frontend and API to query PDF-based Data Structures & Algorithms materials. The project extracts text from PDFs, creates embeddings, stores them in PostgreSQL (with pgvector), and uses a Groq LLM for context-aware answers.

## Quick summary

- Web app: `app.py` serves a simple frontend and two endpoints: `POST /ingest` to ingest PDFs and `POST /ask` to query.
- PDF loading & splitting: `loaders/pdf_loader.py` uses PyMuPDF via LangChain community loader and splits into chunks.
- Embeddings: `embeddings/embedder.py` creates embeddings via `HuggingFaceEmbeddings` configured in `config.py`.
- Vector store: `db/vector_store.py` stores and searches embeddings in PostgreSQL (`documents` table).
- LLM: `llm/groq_llm.py` wraps the Groq Chat model; prompts are composed in `rag/rag_pipeline.py`.

## Prerequisites

- Python 3.8+
- PostgreSQL with the `pgvector` extension
- A Groq API key (set in environment variable `GROQ_API_KEY`)

## Install

1. Create and activate a virtual environment:

```bash
python -m venv venv
# Windows
venv\Scripts\activate
# macOS / Linux
source venv/bin/activate
```

2. Install dependencies:

```bash
pip install -r requirements.txt
```

3. Create the database and extension (example using psql):

```sql
CREATE DATABASE rag_db;
\c rag_db
CREATE EXTENSION IF NOT EXISTS vector;
```

4. Create the `documents` table used by the code:

```sql
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    content TEXT,
    embedding VECTOR(384)
);
```

Update `DB_CONFIG` in `config.py` if your database credentials differ.

## Configuration

Edit `config.py` or use a `.env` file to set environment variables. Relevant values in `config.py`:

- `PDF_DIR` â€” default: `data/pdf` (where PDF files should be placed)
- `DB_CONFIG` â€” connection information for PostgreSQL
- `EMBEDDING_MODEL` â€” Hugging Face model name used for embeddings
- `GROQ_MODEL` and `GROQ_API_KEY` â€” Groq LLM configuration

## Usage

1. Place your PDF files into the `data/pdf/` directory.

2. Start the Flask server:

```bash
python app.py
```

3. Ingest PDFs (via the server endpoint):

```bash
curl -X POST http://localhost:5000/ingest
```

The `/ingest` endpoint runs `load_and_split_pdfs_from_directory(PDF_DIR)` and then `store_documents(...)` to save embeddings to the database.

4. Ask a question (example):

```bash
curl -X POST http://localhost:5000/ask \
  -H "Content-Type: application/json" \
  -d '{"question":"What is a binary search tree?"}'
```

The request calls `rag.rag_pipeline.rag_answer(question)`, which performs a similarity search and invokes the Groq LLM with the retrieved context.

## Files & Responsibilities

- `app.py` â€” Flask app with `/` (frontend), `/ingest`, and `/ask` endpoints.
- `loaders/pdf_loader.py` â€” Finds PDFs in `data/pdf/`, loads them using PyMuPDF and splits text into chunks.
- `embeddings/embedder.py` â€” Returns the `HuggingFaceEmbeddings` model used to embed text.
- `db/connection.py` â€” Returns a psycopg2 connection using `DB_CONFIG` from `config.py`.
- `db/vector_store.py` â€” `store_documents(chunks)` inserts text+embedding into `documents`; `similarity_search(query, top_k=5)` returns concatenated text results.
- `llm/groq_llm.py` â€” Builds a `ChatGroq` client used to invoke the LLM.
- `rag/rag_pipeline.py` â€” Composes prompt, retrieves context via `similarity_search`, and calls the LLM.
- `templates/index.html` & `static/script.js` â€” Minimal frontend to ask questions and display answers.
- `main.py` â€” tiny CLI stub.

## Notes & Recommendations

- Security: Keep `GROQ_API_KEY` and DB credentials out of version control; use a `.env` file or secrets manager.
- Embedding dimensionality: The code assumes a 384-dim model (see `EMBEDDING_MODEL` in `config.py`). If you change the model, update the database `VECTOR(...)` size accordingly.
- Production: For concurrency and stability, run the Flask app behind a production server (e.g., Gunicorn) and secure the DB and API keys.

## Troubleshooting

- If ingestion reports no PDFs: confirm files are in `data/pdf/` and `PDF_DIR` path in `config.py` is correct.
- Database connection errors: verify PostgreSQL is running and `DB_CONFIG` matches your credentials.
- LLM errors: ensure `GROQ_API_KEY` is set and the configured `GROQ_MODEL` is available.

## Contributing

Contributions welcome. Typical flow:

1. Fork and create a feature branch
2. Add tests/local verification
3. Open a PR

## License

See repository license (if present).

---

If you'd like, I can also:

- Add a sample `.env.example` file
- Add a small script to initialize the DB schema
- Add a short guide to deploy the Flask app behind Gunicorn

# ğŸ“ DSA RAG - Data Structures & Algorithms RAG System

> An intelligent **Retrieval-Augmented Generation (RAG)** system for Data Structures & Algorithms learning

A powerful AI-driven tutoring system that enables intelligent Q&A over DSA educational materials using cutting-edge LLMs and vector databases.

## ğŸš€ Overview

DSA RAG is an **AI-powered tutoring system** that processes PDF documents containing DSA concepts and provides accurate, context-aware answers to user queries. 

### Key Components:

| Component | Description |
|-----------|-------------|
| ğŸ“„ **Document Processing** | Loads and processes PDF documents intelligently |
| ğŸ§® **Embeddings** | Converts text into vector embeddings using sentence transformers |
| ğŸ—„ï¸ **Vector Database** | Stores embeddings in PostgreSQL with pgvector extension |
| ğŸ¤– **LLM Integration** | Uses Groq's API for ultra-fast inference |
| ğŸ”„ **RAG Pipeline** | Retrieves relevant context and generates accurate answers |

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   User Query    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Similarity Search      â”‚
â”‚   (Vector Database)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Context Retrieval      â”‚
â”‚  (Top-K Results)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LLM Processing         â”‚
â”‚  (Groq API)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Generated Answer       â”‚
â”‚  (Context-Aware)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
DSA_RAG/
â”œâ”€â”€ ğŸ“„ app.py                 # Main application entry point
â”œâ”€â”€ âš™ï¸  config.py              # Configuration settings
â”œâ”€â”€ ğŸš€ main.py                # CLI interface
â”œâ”€â”€ ğŸ“‹ requirements.txt       # Python dependencies
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”œâ”€â”€ ğŸ“š pdf/              # PDF documents (DSA books/materials)
â”‚   â””â”€â”€ ğŸ“ text/             # Text files
â”œâ”€â”€ ğŸ—„ï¸  db/
â”‚   â”œâ”€â”€ ğŸ”— connection.py      # Database connection utilities
â”‚   â””â”€â”€ ğŸ” vector_store.py    # Vector store and similarity search
â”œâ”€â”€ ğŸ§® embeddings/
â”‚   â””â”€â”€ ğŸ“Š embedder.py        # Text embedding functions
â”œâ”€â”€ ğŸ¤– llm/
â”‚   â””â”€â”€ ğŸ’¬ groq_llm.py        # Groq LLM integration
â”œâ”€â”€ ğŸ“¦ loaders/
â”‚   â””â”€â”€ ğŸ“¥ pdf_loader.py      # PDF document loading
â””â”€â”€ ğŸ”„ rag/
    â””â”€â”€ âš¡ rag_pipeline.py    # RAG pipeline logic
```

## ğŸ“¥ Installation

### âœ… Prerequisites

- Python 3.8+
- PostgreSQL with pgvector extension
- Groq API key

### ğŸ”§ Setup Steps

1. **ğŸ“¦ Clone the repository**
   ```bash
   git clone https://github.com/Amrit114/DSA_RAG.git
   cd DSA_RAG
   ```

2. **ğŸ Create a virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **ğŸ“š Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **ğŸ” Configure environment variables**
   Create a `.env` file in the project root:
   ```env
   GROQ_API_KEY=your_groq_api_key_here
   DB_NAME=rag_db
   DB_USER=postgres
   DB_PASSWORD=your_password
   DB_HOST=localhost
   DB_PORT=5432
   ```

5. **ğŸ—„ï¸  Setup PostgreSQL**
   ```sql
   CREATE DATABASE rag_db;
   CREATE EXTENSION IF NOT EXISTS vector;
   ```

6. **ğŸ“„ Add DSA materials**
   - Place PDF files in `data/pdf/` directory
   - Update the `PDF_PATH` in `config.py` if needed

## ğŸ“š Usage

### Loading Documents

Documents are automatically loaded from the configured PDF path. The system:
1. Extracts text from PDFs
2. Splits text into chunks
3. Generates embeddings
4. Stores in vector database

### ğŸ” Running Queries

```python
from rag.rag_pipeline import rag_answer

question = "What is a binary search tree?"
answer = rag_answer(question)
print(answer)
```

### ğŸ’» Command Line Interface

```bash
python main.py
```

## ğŸ› ï¸ Technologies Used

| Technology | Purpose |
|-----------|---------|
| **LangChain** | LLM framework and orchestration |
| **Groq** | âš¡ Fast LLM inference API |
| **Sentence Transformers** | Text embedding model (384-dim) |
| **PostgreSQL + pgvector** | ğŸ—„ï¸ Vector database |
| **PyPDF/PyMuPDF** | PDF document loading |
| **Python-dotenv** | Environment variable management |

## ğŸ’¾ Database Schema

The system uses PostgreSQL with pgvector extension for storing and searching embeddings.

### Documents Table

```sql
CREATE TABLE documents (
    id SERIAL PRIMARY KEY,
    content TEXT,
    embedding VECTOR(384)
);
```

### ğŸ“Š Schema Details

| Column | Type | Description |
|--------|------|-------------|
| `id` | SERIAL PRIMARY KEY | Unique document identifier |
| `content` | TEXT | Document text content |
| `embedding` | VECTOR(384) | 384-dimensional vector representation (from sentence-transformers) |

### ğŸ”‘ Indexes (Recommended for Performance)

```sql
-- Create index for vector similarity search
CREATE INDEX ON documents USING ivfflat (embedding vector_cosine_ops);

-- Create index for faster lookups
CREATE INDEX ON documents(id);
```

### ğŸ’¡ Usage Example

```python
# Embeddings are automatically generated and stored
# Vector search is performed using cosine similarity
from db.vector_store import similarity_search

results = similarity_search("binary search tree", k=5)
# Returns top 5 most similar documents
```

## ğŸ“¦ Dependencies

See [requirements.txt](requirements.txt) for complete list:

```
langchain                 # LLM orchestration framework
langchain-groq           # Groq API integration
sentence-transformers    # Text embeddings
psycopg2-binary         # PostgreSQL adapter
pgvector                # Vector extension for PostgreSQL
pypdf                   # PDF processing
python-dotenv           # Environment variables
```

## âœ¨ Features

âœ… **Multi-document PDF processing** - Handle multiple PDF files  
âœ… **Vector similarity search** - Fast semantic search using pgvector  
âœ… **Context-aware LLM responses** - Intelligent answers based on retrieved context  
âœ… **PostgreSQL integration** - Robust database backend  
âœ… **Fast inference** - Powered by Groq API  
âœ… **Customizable embeddings** - Choose your embedding model  
âœ… **Easy configuration** - Simple config.py for setup  

## ğŸ” API Keys & Credentials

âš ï¸ **Security Note**: Never commit API keys or credentials. Use `.env` file for sensitive information.

### ğŸ”‘ Getting API Keys

1. **Groq API**: Sign up at [console.groq.com](https://console.groq.com) âš¡
2. **PostgreSQL**: Set up locally or use cloud provider â˜ï¸

## ğŸ—ºï¸ Roadmap

- [ ] ğŸŒ Web UI (Streamlit/FastAPI)
- [ ] ğŸ“„ Support for multiple document formats
- [ ] ğŸ¯ Fine-tuned embeddings
- [ ] ğŸ’¬ Conversation history tracking
- [ ] ğŸ“Œ Answer source citation
- [ ] ğŸ“Š Performance analytics
- [ ] ğŸ”” Real-time updates

## ğŸ› Troubleshooting

### ğŸ—„ï¸ Database Connection Issues
```
âŒ Error: Connection refused
âœ… Solution: Ensure PostgreSQL is running and DB_CONFIG is correct
```

### ğŸ§® Embedding Generation Errors
```
âŒ Error: Model not found
âœ… Solution: Check internet connection and disk space for model download
```

### ğŸ¤– LLM Response Issues
```
âŒ Error: API key invalid
âœ… Solution: Verify Groq API key and check rate limits
```

## ğŸ¤ Contributing

Contributions are welcome! Please:

1. ğŸ´ Fork the repository
2. ğŸŒ¿ Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. ğŸ’¾ Commit changes (`git commit -m 'Add some AmazingFeature'`)
4. ğŸš€ Push to the branch (`git push origin feature/AmazingFeature`)
5. ğŸ“ Open a Pull Request

## ğŸ“„ License

This project is open source. Check LICENSE file for details.

## ğŸ“ Contact & Support

- **ğŸ‘¤ Author**: [Amrit Raj singh](https://github.com/Amrit114)
- **ğŸ“¦ Repository**: [DSA_RAG](https://github.com/Amrit114/DSA_RAG)
- **ğŸ› Issues**: [Report bugs on GitHub](https://github.com/Amrit114/DSA_RAG/issues)

## ğŸ™ Acknowledgments

- âš¡ **Groq** - for fast LLM inference
- ğŸ”— **LangChain** - for excellent LLM orchestration
- ğŸ¤— **Hugging Face** - for sentence transformers
- ğŸ˜ **PostgreSQL** - for pgvector extension
- ğŸ“ **DSA Community** - for educational resources
